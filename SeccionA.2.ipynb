{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seccion A.2\n",
    "## Datos abiertos de la CDMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alcaldias = [\n",
    "    'Milpa Alta',\n",
    "    'Benito Juarez',\n",
    "    'Gustavo A Madero',\n",
    "    'Coyoacan',\n",
    "    'Miguel Hidalgo',\n",
    "    'La Magdalena Contreras',\n",
    "    'Tlahuac',\n",
    "    'Azcapotzalco',\n",
    "    'Iztacalco',\n",
    "    'Alvaro Obregon',\n",
    "    'Xochimilco',\n",
    "    'Venustiano Carranza',\n",
    "    'Tlalpan',\n",
    "    'Cuajimalpa de Morelos',\n",
    "    'Cuauhtemoc',\n",
    "    'Iztapalapa'\n",
    "]\n",
    "alcaldias = list(map(str.upper, alcaldias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"carpetas-de-investigacion-pgj-de-la-ciudad-de-mexico.csv\")\n",
    "## We delete all the crimes that do not correspond to cdmx alcaldias\n",
    "mask_alcaldias_cdmx = data.apply(lambda x: True if x['alcaldia_hechos'] in alcaldias else False, axis=1)\n",
    "data = data.where(mask_alcaldias_cdmx).dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CUAUHTEMOC                170940\n",
       "IZTAPALAPA                162469\n",
       "GUSTAVO A MADERO          108085\n",
       "BENITO JUAREZ              91470\n",
       "ALVARO OBREGON             72407\n",
       "COYOACAN                   72039\n",
       "MIGUEL HIDALGO             70935\n",
       "TLALPAN                    63076\n",
       "VENUSTIANO CARRANZA        62448\n",
       "AZCAPOTZALCO               52272\n",
       "IZTACALCO                  45181\n",
       "XOCHIMILCO                 33490\n",
       "TLAHUAC                    25594\n",
       "LA MAGDALENA CONTRERAS     16938\n",
       "CUAJIMALPA DE MORELOS      15634\n",
       "MILPA ALTA                  7261\n",
       "Name: alcaldia_hechos, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['alcaldia_hechos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Which test would you do to ensure the quality of this data?\n",
    "I would check for the columns unique values, specifically for the ones that are not very numerous, like 'ao_hechos' or the ones that can contain strings, accents tend to cause problems due to its different codification.\n",
    "\n",
    "If there are error, I would try to correct them and if I can't then I would drop those malformed rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "How many crimes are registered in the table? What is the time range of these crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1070239 registered crimes\n",
      "The time range of this table goes from the years 1906 to 2020\n"
     ]
    }
   ],
   "source": [
    "registered_crimes = data.shape[0]\n",
    "print(f'There are {registered_crimes} registered crimes')\n",
    "\n",
    "last_registered_year = data['ao_hechos'].max()\n",
    "first_registered_year = data['ao_hechos'].min()\n",
    "print(f'The time range of this table goes from the years {first_registered_year:.0f} to {last_registered_year:.0f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "How are the crimes distributed in Mexico city? Which are the 5 most commited crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 most commited crime are: \n",
      "VIOLENCIA FAMILIAR                                102671\n",
      "ROBO A NEGOCIO SIN VIOLENCIA                       64689\n",
      "ROBO DE OBJETOS                                    64661\n",
      "FRAUDE                                             62872\n",
      "ROBO A TRANSEUNTE EN VIA PUBLICA CON VIOLENCIA     54935\n",
      "Name: delito, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_5 = data['delito'].value_counts()[:5]\n",
    "print(f'The 5 most commited crime are: \\n{top_5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Identify the crime that are increasing and the ones decreasing compared to the last year (2019)? (be careful with low ocurrency crimes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is just as a reminder for myself in which ways this can be solved\n",
    "## Option 1\n",
    "crimes_per_year = data.where(data['ao_hechos']>=2019).groupby(['delito', 'ao_hechos']).agg(count = pd.NamedAgg(column = 'ao_hechos', aggfunc = 'count' ))\n",
    "## option 2\n",
    "data.where(data['ao_hechos']>=2019).groupby(['delito', 'ao_hechos']).size().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrong_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f90775d89dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#It would be easier to map all the accents to their wrong equivalent i.e. í: Ã, ó:Ã“\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mright_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrong_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrong_string\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/EMTech/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7543\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7544\u001b[0m         )\n\u001b[0;32m-> 7545\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EMTech/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EMTech/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/EMTech/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f90775d89dec>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#It would be easier to map all the accents to their wrong equivalent i.e. í: Ã, ó:Ã“\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mright_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrong_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwrong_string\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'delito'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'wrong_string' is not defined"
     ]
    }
   ],
   "source": [
    "wrong_char = ['Ã“', 'Ã', 'Ã‰', 'Ãš', 'Ã\\x81']\n",
    "                \n",
    "right_char = ['Ó', 'Í', 'É','Ú', 'Á']\n",
    "\n",
    "#It would be easier to map all the accents to their wrong equivalent i.e. í: Ã, ó:Ã“\n",
    "data['delito'] = data.apply(lambda row:  right_string[wrong_string.index(row['delito'])] if row['delito'] in wrong_string else row['delito'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_string = ['PRODUCCIÃ“N, IMPRESIÃ“N, ENAJENACIÃ“N, DISTRIBUCIÃ“N, ALTERACIÃ“N O FALSIFICACIÃ“N DE TÃTULOS AL PORTADOR, DOCUMENTOS DE CRÃ‰DITO PÃšBLICOS O VALES DE CANJE',\n",
    "                'USURPACIÃ“N DE IDENTIDAD']\n",
    "                \n",
    "right_string = ['PRODUCCIÓN, IMPRESIÓN, ENAJENACIÓN, DISTRIBUCIÓN, ALTERACIÓN O FALSIFICACIÓN DE TÍTULOS AL PORTADOR, DOCUMENTOS DE CRÉDITO PÚBLICOS O VALES DE CANJE',\n",
    "               'USURPACIÓN DE IDENTIDAD']\n",
    "\n",
    "#It would be easier to map all the accents to their wrong equivalent i.e. í: Ã, ó:Ã“\n",
    "data['delito'] = data.apply(lambda row:  right_string[wrong_string.index(row['delito'])] if row['delito'] in wrong_string else row['delito'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year = data.where(data['ao_hechos']>=2019).value_counts(['delito', 'ao_hechos']).to_frame()\n",
    "crimes_per_year = crimes_per_year.unstack(fill_value=0)\n",
    "crimes_per_year.columns = crimes_per_year.columns.droplevel(0)\n",
    "crimes_per_year.columns.name = None\n",
    "crimes_per_year.columns = crimes_per_year.columns.astype('int64').astype('string')\n",
    "\n",
    "# Create the increase column, if negative is a decrease\n",
    "crimes_per_year['% increase@2020-2019'] = (crimes_per_year['2020']-crimes_per_year['2019'])*100/crimes_per_year['2019']\n",
    "\n",
    "# We need to set a threshold in the number of crimes\n",
    "# Remove crimes in 2020 that equal zero\n",
    "crimes_per_year = crimes_per_year.where(crimes_per_year['2019']>50).dropna()\n",
    "crimes_per_year = crimes_per_year.where(crimes_per_year['2020']>50).dropna()\n",
    "crimes_per_year = crimes_per_year.sort_values(by=['% increase@2020-2019'], ascending=False)\n",
    "crimes_per_year.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year.iloc[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year = data.where((data['ao_hechos']>=2018) & (data['ao_hechos']<2020)).value_counts(['delito', 'ao_hechos']).to_frame()\n",
    "crimes_per_year = crimes_per_year.unstack(fill_value=0)\n",
    "crimes_per_year.columns = crimes_per_year.columns.droplevel(0)\n",
    "crimes_per_year.columns.name = None\n",
    "crimes_per_year.columns = crimes_per_year.columns.astype('int64').astype('string')\n",
    "\n",
    "# Create the increase column, if negative is a decrease\n",
    "crimes_per_year['% increase@2019-2018'] = (crimes_per_year['2019']-crimes_per_year['2018'])*100/crimes_per_year['2018']\n",
    "\n",
    "# We need to set a threshold in the number of crimes\n",
    "# Remove crimes in 2020 that equal zero\n",
    "crimes_per_year = crimes_per_year.where(crimes_per_year['2018']>50).dropna()\n",
    "crimes_per_year = crimes_per_year.where(crimes_per_year['2019']>50).dropna()\n",
    "crimes_per_year = crimes_per_year.sort_values(by=['% increase@2019-2018'], ascending=False)\n",
    "crimes_per_year.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_year.iloc[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Which \"alcaldia\" has the most crimes and which one the least? Why do you think is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['alcaldia_hechos'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "Inside each \"alcaldia\", which are the three neighborhoods with the most crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_neighborhood = data.value_counts(['alcaldia_hechos', 'colonia_hechos']).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_neighborhood.columns = ['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_neighborhood = crimes_per_neighborhood.sort_values(['alcaldia_hechos', 'count'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alcaldia in alcaldias:\n",
    "    print(f'The three neighborhoods with the most crimes in {alcaldia} are :\\n {crimes_per_neighborhood.loc[alcaldia].head(3)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Is there any seasonal tendency in crimes? (monthly, weekly, biweekly, day of the week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency = data.copy()\n",
    "\n",
    "#We need to drop the dates that does not have a valid timestamp\n",
    "def into_timestamp(row):\n",
    "    try:\n",
    "        return pd.Timestamp(row).date()\n",
    "    \n",
    "    except:\n",
    "        return np.NaN\n",
    "    \n",
    "seasonal_tendency['fecha_hechos'] = seasonal_tendency['fecha_hechos'].apply(lambda row: into_timestamp(row)) # This may not be the cleanest solution\n",
    "seasonal_tendency = seasonal_tendency.dropna(subset=['fecha_hechos'])\n",
    "seasonal_tendency['fecha_hechos'] = pd.to_datetime(seasonal_tendency['fecha_hechos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency['month'] = seasonal_tendency['fecha_hechos'].dt.month\n",
    "seasonal_tendency['week_day'] = seasonal_tendency['fecha_hechos'].dt.weekday\n",
    "seasonal_tendency['weekly'] = seasonal_tendency['fecha_hechos'].dt.week\n",
    "seasonal_tendency['biweekly'] = seasonal_tendency['weekly']//2 + (seasonal_tendency['weekly'] % 2 > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency.value_counts('week_day').sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency.value_counts('month').sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency.value_counts('weekly').sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_tendency.value_counts('biweekly').sort_index().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a first analysis (visual analysis of plots) it seems as if the crime tends to decrease in the last weeks and months of the year. And also on sundays. It also tends to increase on fridays. Further analysis would be needed to determine if this is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Which are the crimes that characterize each 'alcaldia'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_per_alcaldia = data.value_counts(['delito','alcaldia_hechos']).to_frame()\n",
    "crimes_per_alcaldia.columns = ['count']\n",
    "crimes_per_alcaldia = crimes_per_alcaldia.groupby('delito').head(1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_exclusive_crime = []\n",
    "for alcaldia in alcaldias:\n",
    "    try:\n",
    "        aux = crimes_per_alcaldia.where(crimes_per_alcaldia['alcaldia_hechos'] == alcaldia).dropna().iloc[0].to_list()\n",
    "        top_exclusive_crime.append(aux)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top_exclusive_crime, columns=crimes_per_alcaldia.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "Calcula el número de homicidios dolosos por cada 100 mil habitantes anual para cada Área Geoestadística Básica (AGEB) del INEGI. (hint: no importa que el dato de población no esté actualizado).\n",
    "a) Pinta un mapa con este indicador. Describe los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "¿Cómo diseñarías un indicador que midiera el nivel “inseguridad”? Diséñalo al nivel de\n",
    "desagregación que te parezca más adecuado (ej. manzana, calle, AGEB, etc.).\n",
    "\n",
    "En mi opinion lo realizaria a nivel de colonia. Podria hacerse un conteo de los delitos en cada colonia, dandole un peso diferente a cada uno de ellos. Homicidios, violaciones y secuestros tendrian un mayor peso que el resto de las categorias de delitos. Este puntaje se escalaria a un rango de cero a diez, en donde cero es el minimo y diez el maximo. Cada colonia tendria un puntaje con base en esto. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "Con alguna de las medidas de crimen que calculaste en los incisos anteriores, encuentra\n",
    "patrones de concentración geográfica de delitos (hint: puedes usar algoritmos de\n",
    "Machine Learning no supervisados).\n",
    "a) ¿Qué caracteriza a cada punto de concentración de delitos y qué tienen en\n",
    "común?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 12\n",
    "Toma los delitos clasificados como “Robo a pasajero a bordo de transporte público con\n",
    "y sin violencia”. ¿Cuáles son las ruta de transporte público donde más ocurren estos\n",
    "delitos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crimes_list = list(data['delito'].unique())\n",
    "public_transport_crimes_list = [row  for row in crimes_list if ('ROBO A PASAJERO' in row) and ('CONDUCTOR' not in row)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data['categoria_delito'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the crimes that involve public transport\n",
    "mask_transport_crimes = data.apply(lambda x: True if x['delito'] in public_transport_crimes_list else False, axis=1)\n",
    "public_transport_df = data.where(mask_transport_crimes).dropna(how='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_transport_df.value_counts(['calle_hechos']).to_frame().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
